{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ML_parameters_algorithm_20200821_v04.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"dn6I8EX-x0ms","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":128},"executionInfo":{"status":"ok","timestamp":1598014647838,"user_tz":-330,"elapsed":31286,"user":{"displayName":"Preksha Visualizer","photoUrl":"","userId":"00219913212111536034"}},"outputId":"38c37f2c-44da-4c2a-a2dc-d2143f0cc63b"},"source":["import numpy as np \n","import pandas as pd \n","import matplotlib.pyplot as plt\n","from scipy import stats\n","from sklearn.metrics import r2_score\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9uhTM99Vx8GE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":201},"executionInfo":{"status":"ok","timestamp":1598014772167,"user_tz":-330,"elapsed":1338,"user":{"displayName":"Preksha Visualizer","photoUrl":"","userId":"00219913212111536034"}},"outputId":"a8ae3fa9-0e31-43d4-94a2-1d0851e3e72a"},"source":["#df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/2020_Intern_12__T​RI01_Comp/2020_08-03_2020_Intern_12_TRI01_Comp_Parameter_v01.csv', skiprows=1)\n","df = pd.read_csv('/content/gdrive/My Drive/2020_Intern_12_T​RI01_Comp/2020_08-03_2020_Intern_12_TRI01_Comp_Parameter_v01.csv', skiprows=1)\n","\n","print(df.head())\n","print(df.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["   Whether the scene is able to convey the same message of input text? ???? ????? ??? ????? ??????? ?? ??? ???? ???? ??? ?? ??? ??? ?? ?  ...  How much difficult is the input text to be visualized by human? ?????? ?????? ?????? ???? ?? ???, ????? ??????? ????? ??????? ???\n","0                                                  4                                                                                      ...                                                  0                                                                                \n","1                                                  3                                                                                      ...                                                  1                                                                                \n","2                                                  3                                                                                      ...                                                  0                                                                                \n","3                                                  2                                                                                      ...                                                  3                                                                                \n","4                                                  4                                                                                      ...                                                  1                                                                                \n","\n","[5 rows x 10 columns]\n","(1022, 10)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RofEJCNj-YiW","colab_type":"code","colab":{}},"source":["ques1 = \"Whether the scene is able to convey the same message of input text? ???? ????? ??? ????? ??????? ?? ??? ???? ???? ??? ?? ??? ??? ?? ?\"\n","ques2 = \"Whether the scene has sufficient number of objects as per the requirement to show the meaning of input text? ????? ??????? ?? ???? ??, ???? ????? ??? ???????? ???????? ?????? ??? ??? ?\"\n","ques3 = \"Depending on the input text, whether the objects shown in the scene are properly placed? ????? ??????? ?? ???? ??, ???? ????? ??? ??????? ??? ??????? ???? ??? ?? ??? ??? ????\"\n","ques4 = \"Whether the colour mentioned of objects in the scene is appropriate according to Input Text? ????? ??????? ?? ???? ??, ???? ????? ??? ??????? ??? ??????? ?? ??? ?? ??????? ??????? ??? \"\n","ques5 = \"Whether the size, shape and texture of mentioned objects in the scene is appropriate according to Input Text? ????? ??????? ?? ???? ??, ???? ????? ??? ??????? ??? ??????? ?? ??????(????) ?? ???? ??????? ???\"\n","ques6 = \"Whether the background of scene is chosen properly according to Input Text? ????? ??????? ?? ???? ??, ???? ????? ?? ????????? ??????? ???\"\n","ques7 = \"Whether the scene is able to convey any message without taking reference of input text????? ????? ????????? ?? ?? ????? ??????? ?? ??? ???? ?? ??? ???? ?? ???? ???\"\n","ques8 = \"Whether the scene composition is realistic? ???? ????? ?????? ???????? ?? ?\"\n","ques9 = \"Whether the object orientation are appropriate in the scene? ???? ????? ??? ??????? ?? ?????/????? ??????? ???\"\n","ques10 = \"How much difficult is the input text to be visualized by human? ?????? ?????? ?????? ???? ?? ???, ????? ??????? ????? ??????? ???\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"33HIVq1tDWds","colab_type":"code","colab":{}},"source":["#Have approx 80% i.e. 818 available for training and 20% for testing\n","\n","fid1_train = df.loc[:817,ques1].values\n","fid2_train = df.loc[:817,ques2].values\n","fid3_train = df.loc[:817,ques3].values\n","fid4_train = df.loc[:817,ques4].values\n","fid5_train = df.loc[:817,ques5].values\n","fid6_train = df.loc[:817,ques6].values\n","\n","int1_train = df.loc[:817,ques7].values\n","int2_train = df.loc[:817,ques8].values\n","int3_train = df.loc[:817,ques9].values\n","\n","subparams_fid_int_train = [fid1_train,fid2_train,fid3_train,fid4_train,fid5_train,fid6_train,int1_train,int2_train,int3_train]\n","\n","comp_train = df.loc[:817,ques10].values\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AwyoS1pWHGQT","colab_type":"code","colab":{}},"source":["#Checking\n","#print(fid6_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mC0wwZz0jYmU","colab_type":"code","colab":{}},"source":["combos_train = [[list(i),list(comp_train)] for i in subparams_fid_int_train]\n","\n","#Checking\n","#print(combos_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cayM_EeKoxIo","colab_type":"code","colab":{}},"source":["fid1_test = df.loc[818:,ques1].values\n","fid2_test = df.loc[818:,ques2].values\n","fid3_test = df.loc[818:,ques3].values\n","fid4_test = df.loc[818:,ques4].values\n","fid5_test = df.loc[818:,ques5].values\n","fid6_test = df.loc[818:,ques6].values\n","\n","int1_test = df.loc[818:,ques7].values\n","int2_test = df.loc[818:,ques8].values\n","int3_test = df.loc[818:,ques9].values\n","\n","subparams_fid_int_test = [fid1_test,fid2_test,fid3_test,fid4_test,fid5_test,fid6_test,int1_test,int2_test,int3_test]\n","\n","comp_test = df.loc[818:,ques10].values\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cc3VqXTnoxa3","colab_type":"code","colab":{}},"source":["#Checking\n","#print(int2_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"71wPpqyFoxp-","colab_type":"code","colab":{}},"source":["combos_test = [[list(i),list(comp_train)] for i in subparams_fid_int_test]\n","\n","#Checking\n","#print(combos_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sqIYGBNjJqTq","colab_type":"code","colab":{}},"source":["def simple_linear_regression(x,y):\n","    m,c,r = stats.linregress(x,y)[0], stats.linregress(x,y)[1], stats.linregress(x,y)[2]\n","    return \"y = %f * x + %f with r = %f\" %(m,c,r)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xU2YnjCOjeBL","colab_type":"code","colab":{}},"source":["def polynomial_regression_order_2(x,y):\n","    model_fit_o2 = np.poly1d(np.polyfit(x,y,2))\n","    return \"The polynomial fit is \\n %s and r^2 score is %f\" %(model_fit_o2, r2_score(y,model_fit_o2(x)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IkKHVmfmjeN-","colab_type":"code","colab":{}},"source":["def polynomial_regression_order_3(x,y):\n","    model_fit_o3 = np.poly1d(np.polyfit(x,y,3))\n","    return \"The polynomial fit is \\n %s and r^2 score is %f\" %(model_fit_o3, r2_score(y,model_fit_o3(x)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yXjcvFwQjeYv","colab_type":"code","colab":{}},"source":["def polynomial_regression_order_4(x,y):\n","    model_fit_o4 = np.poly1d(np.polyfit(x,y,4))\n","    return \"The polynomial fit is \\n %s and r^2 score is %f\" %(model_fit_o4, r2_score(y,model_fit_o4(x)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_29NhO__jemQ","colab_type":"code","colab":{}},"source":["def polynomial_regression_order_5(x,y):\n","    model_fit_o5 = np.poly1d(np.polyfit(x,y,5))\n","    return \"The polynomial fit is \\n %s and r^2 score is %f\" %(model_fit_o5, r2_score(y,model_fit_o5(x)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eUM4aMZqjex8","colab_type":"code","colab":{}},"source":["def polynomial_regression_order_8(x,y):\n","    model_fit_o8 = np.poly1d(np.polyfit(x,y,8))\n","    return \"The polynomial fit is \\n %s and r^2 score is %f\" %(model_fit_o8, r2_score(y,model_fit_o8(x)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XRClkdNSjvQw","colab_type":"code","colab":{}},"source":["regressions = [\"simple_linear_regression\",\"polynomial_regression_order_2\",\"polynomial_regression_order_3\",\"polynomial_regression_order_4\", \"polynomial_regression_order_5\",\"polynomial_regression_order_8\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gJ0n4vWHj02U","colab_type":"code","colab":{}},"source":["#These provide a baseline and suggest linear regression is most apt\n","\n","def execute_func(x,y):\n","    functions = [simple_linear_regression(x,y), polynomial_regression_order_2(x,y), polynomial_regression_order_3(x,y), polynomial_regression_order_4(x,y), polynomial_regression_order_5(x,y), polynomial_regression_order_8(x,y)]\n","    #Create a dictionary comprehension\n","    options = {regressions[i]:functions[i] for i in range(len(regressions))}\n","\n","    for i in regressions:\n","        print(options[i])\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x0yHOZNhUL_N","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1598011508027,"user_tz":-60,"elapsed":1249,"user":{"displayName":"Rahul Banerjee","photoUrl":"","userId":"02868075930645419834"}},"outputId":"70796405-0e06-4e08-8a95-6db1aafdfc51"},"source":["for j in range(len(subparams_fid_int_train)):\n","  if (j < 6):\n","    print(\"fid \" + str(j+1) + \" models \\n\")\n","  else:\n","    print(\"int \" + str(j-5) + \" models \\n\")\n","  execute_func(combos_train[j][0],combos_train[j][1])\n","\n","  print(\"\\n\")\n","\n","#Results are a bit messy but important as they imply that linear regression is likely to be more accurate than polynomial regression"],"execution_count":null,"outputs":[{"output_type":"stream","text":["fid 1 models \n","\n","y = -0.581439 * x + 2.767115 with r = -0.709290\n","The polynomial fit is \n","           2\n","-0.03268 x - 0.4173 x + 2.604 and r^2 score is 0.505370\n","The polynomial fit is \n","          3          2\n","0.05076 x - 0.3798 x + 0.2267 x + 2.358 and r^2 score is 0.511766\n","The polynomial fit is \n","           4          3         2\n","-0.02857 x + 0.2924 x - 1.025 x + 0.7851 x + 2.3 and r^2 score is 0.513072\n","The polynomial fit is \n","           5           4           3          2\n","-0.00582 x + 0.02963 x + 0.08867 x - 0.7343 x + 0.6454 x + 2.3 and r^2 score is 0.513072\n","The polynomial fit is \n","             8             7             6            5           4\n","-5.235e-05 x - 4.709e-05 x + 0.0004509 x + 0.003538 x + 0.01227 x\n","            3          2\n"," - 0.01694 x - 0.4407 x + 0.465 x + 2.3 and r^2 score is 0.513072\n","\n","\n","fid 2 models \n","\n","y = -0.591539 * x + 2.896057 with r = -0.655389\n","The polynomial fit is \n","           2\n","-0.02619 x - 0.4514 x + 2.738 and r^2 score is 0.430516\n","The polynomial fit is \n","          3          2\n","0.07201 x - 0.5533 x + 0.6589 x + 2.143 and r^2 score is 0.438200\n","The polynomial fit is \n","           4           3          2\n","0.004833 x + 0.03007 x - 0.4358 x + 0.5446 x + 2.167 and r^2 score is 0.438228\n","The polynomial fit is \n","             5           4            3          2\n","-0.0006059 x + 0.01089 x + 0.008861 x - 0.4055 x + 0.53 x + 2.167 and r^2 score is 0.438228\n","The polynomial fit is \n","             8             7             6            5            4\n","-2.174e-05 x - 4.152e-06 x + 0.0002956 x + 0.001895 x + 0.005104 x\n","            3          2\n"," - 0.02329 x - 0.3122 x + 0.4719 x + 2.167 and r^2 score is 0.438228\n","\n","\n","fid 3 models \n","\n","y = -0.607938 * x + 2.834331 with r = -0.724779\n","The polynomial fit is \n","           2\n","-0.07082 x - 0.2438 x + 2.451 and r^2 score is 0.534498\n","The polynomial fit is \n","          3          2\n","0.04192 x - 0.3637 x + 0.3267 x + 2.191 and r^2 score is 0.538320\n","The polynomial fit is \n","           4          3          2\n","-0.01158 x + 0.1408 x - 0.6328 x + 0.572 x + 2.154 and r^2 score is 0.538539\n","The polynomial fit is \n","            5           4           3          2\n","-0.002867 x + 0.01709 x + 0.04041 x - 0.4895 x + 0.5032 x + 2.154 and r^2 score is 0.538539\n","The polynomial fit is \n","             8             7             6            5            4\n","-3.167e-05 x - 2.245e-05 x + 0.0003131 x + 0.002272 x + 0.007082 x\n","            3         2\n"," - 0.01885 x - 0.323 x + 0.4006 x + 2.154 and r^2 score is 0.538539\n","\n","\n","fid 4 models \n","\n","y = -0.607038 * x + 2.871761 with r = -0.695061\n","The polynomial fit is \n","           2\n","-0.07628 x - 0.212 x + 2.448 and r^2 score is 0.494151\n","The polynomial fit is \n","          3          2\n","0.03871 x - 0.3438 x + 0.2945 x + 2.243 and r^2 score is 0.497472\n","The polynomial fit is \n","           4         3         2\n","-0.04662 x + 0.439 x - 1.439 x + 1.281 x + 2.133 and r^2 score is 0.500512\n","The polynomial fit is \n","            5           4          3         2\n","-0.008824 x + 0.04162 x + 0.1302 x - 0.998 x + 1.069 x + 2.133 and r^2 score is 0.500512\n","The polynomial fit is \n","             8             7             6            5          4\n","-7.343e-05 x - 7.093e-05 x + 0.0005947 x + 0.004775 x + 0.0167 x\n","            3          2\n"," - 0.02153 x - 0.5771 x + 0.8107 x + 2.133 and r^2 score is 0.500512\n","\n","\n","fid 5 models \n","\n","y = -0.619791 * x + 2.829765 with r = -0.732174\n","The polynomial fit is \n","          2\n","-0.0261 x - 0.4884 x + 2.695 and r^2 score is 0.537420\n","The polynomial fit is \n","           3           2\n","-0.01382 x + 0.06957 x - 0.6716 x + 2.773 and r^2 score is 0.537883\n","The polynomial fit is \n","          4          3          2\n","0.01446 x - 0.1369 x + 0.4026 x - 0.9694 x + 2.812 and r^2 score is 0.538240\n","The polynomial fit is \n","           5           4           3          2\n","0.002743 x - 0.01297 x - 0.04087 x + 0.2655 x - 0.9036 x + 2.812 and r^2 score is 0.538240\n","The polynomial fit is \n","            8             7             6            5            4\n","2.289e-05 x + 2.154e-05 x - 0.0001872 x - 0.001476 x - 0.005081 x\n","             3          2\n"," + 0.005515 x + 0.1359 x - 0.8239 x + 2.813 and r^2 score is 0.538240\n","\n","\n","fid 6 models \n","\n","y = -0.612940 * x + 2.937449 with r = -0.706373\n","The polynomial fit is \n","           2\n","-0.08769 x - 0.1605 x + 2.462 and r^2 score is 0.513259\n","The polynomial fit is \n","          3          2\n","0.02399 x - 0.2558 x + 0.1645 x + 2.326 and r^2 score is 0.514470\n","The polynomial fit is \n","           4          3          2\n","-0.01687 x + 0.1675 x - 0.6422 x + 0.5042 x + 2.286 and r^2 score is 0.514846\n","The polynomial fit is \n","           5           4           3          2\n","-0.00341 x + 0.01723 x + 0.04809 x - 0.4717 x + 0.4223 x + 2.286 and r^2 score is 0.514846\n","The polynomial fit is \n","             8             7             6            5            4\n","-3.143e-05 x - 2.718e-05 x + 0.0002762 x + 0.002118 x + 0.006968 x\n","            3          2\n"," - 0.01484 x - 0.2968 x + 0.3149 x + 2.286 and r^2 score is 0.514846\n","\n","\n","int 1 models \n","\n","y = -0.566825 * x + 2.684401 with r = -0.693812\n","The polynomial fit is \n","           2\n","-0.01321 x - 0.5009 x + 2.619 and r^2 score is 0.481735\n","The polynomial fit is \n","           3           2\n","0.004946 x - 0.04734 x - 0.436 x + 2.592 and r^2 score is 0.481796\n","The polynomial fit is \n","           4          3         2\n","-0.03772 x + 0.3233 x - 0.897 x + 0.3042 x + 2.5 and r^2 score is 0.484256\n","The polynomial fit is \n","            5           4           3          2\n","-0.006468 x + 0.02696 x + 0.09693 x - 0.5736 x + 0.1489 x + 2.5 and r^2 score is 0.484256\n","The polynomial fit is \n","             8             7             6           5           4\n","-4.559e-05 x - 5.264e-05 x + 0.0003103 x + 0.00275 x + 0.01058 x\n","             3          2\n"," - 0.003286 x - 0.2971 x - 0.02042 x + 2.5 and r^2 score is 0.484256\n","\n","\n","int 2 models \n","\n","y = -0.567973 * x + 2.611339 with r = -0.709015\n","The polynomial fit is \n","            2\n","-0.009347 x - 0.523 x + 2.569 and r^2 score is 0.502919\n","The polynomial fit is \n","            3           2\n","-0.003146 x + 0.01152 x - 0.5598 x + 2.581 and r^2 score is 0.502948\n","The polynomial fit is \n","            4           3          2\n","-0.009011 x + 0.07289 x - 0.1911 x - 0.3862 x + 2.567 and r^2 score is 0.503104\n","The polynomial fit is \n","            5            4           3          2\n","-0.001457 x + 0.005562 x + 0.02189 x - 0.1182 x - 0.4211 x + 2.567 and r^2 score is 0.503104\n","The polynomial fit is \n","             8             7             6             5           4\n","-8.767e-06 x - 1.213e-05 x + 4.693e-05 x + 0.0004928 x + 0.00217 x\n","             3           2\n"," + 0.001381 x - 0.06177 x - 0.4556 x + 2.567 and r^2 score is 0.503104\n","\n","\n","int 3 models \n","\n","y = -0.638239 * x + 2.842237 with r = -0.747589\n","The polynomial fit is \n","           2\n","-0.06036 x - 0.3346 x + 2.527 and r^2 score is 0.566009\n","The polynomial fit is \n","            3           2\n","-0.007042 x - 0.01193 x - 0.4268 x + 2.567 and r^2 score is 0.566131\n","The polynomial fit is \n","           4          3          2\n","-0.02345 x + 0.1932 x - 0.5579 x + 0.06866 x + 2.5 and r^2 score is 0.567122\n","The polynomial fit is \n","            5           4           3          2\n","-0.003959 x + 0.01615 x + 0.05466 x - 0.3599 x - 0.02637 x + 2.5 and r^2 score is 0.567122\n","The polynomial fit is \n","            8             7             6            5            4\n","-2.77e-05 x - 3.146e-05 x + 0.0001893 x + 0.001639 x + 0.005993 x\n","             3          2\n"," - 0.005173 x - 0.1937 x - 0.1284 x + 2.5 and r^2 score is 0.567122\n","\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: RankWarning: Polyfit may be poorly conditioned\n","  after removing the cwd from sys.path.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: RankWarning: Polyfit may be poorly conditioned\n","  after removing the cwd from sys.path.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: RankWarning: Polyfit may be poorly conditioned\n","  after removing the cwd from sys.path.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: RankWarning: Polyfit may be poorly conditioned\n","  after removing the cwd from sys.path.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: RankWarning: Polyfit may be poorly conditioned\n","  after removing the cwd from sys.path.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: RankWarning: Polyfit may be poorly conditioned\n","  after removing the cwd from sys.path.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: RankWarning: Polyfit may be poorly conditioned\n","  after removing the cwd from sys.path.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: RankWarning: Polyfit may be poorly conditioned\n","  after removing the cwd from sys.path.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: RankWarning: Polyfit may be poorly conditioned\n","  after removing the cwd from sys.path.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: RankWarning: Polyfit may be poorly conditioned\n","  after removing the cwd from sys.path.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: RankWarning: Polyfit may be poorly conditioned\n","  after removing the cwd from sys.path.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: RankWarning: Polyfit may be poorly conditioned\n","  after removing the cwd from sys.path.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: RankWarning: Polyfit may be poorly conditioned\n","  after removing the cwd from sys.path.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: RankWarning: Polyfit may be poorly conditioned\n","  after removing the cwd from sys.path.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: RankWarning: Polyfit may be poorly conditioned\n","  after removing the cwd from sys.path.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: RankWarning: Polyfit may be poorly conditioned\n","  after removing the cwd from sys.path.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: RankWarning: Polyfit may be poorly conditioned\n","  after removing the cwd from sys.path.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: RankWarning: Polyfit may be poorly conditioned\n","  after removing the cwd from sys.path.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"hyaoijQkssGY","colab_type":"code","colab":{}},"source":["#Now to build the neural network to try multiple regression - some functions have to be defined"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bHAJllJPU1Pd","colab_type":"code","colab":{}},"source":["def round_num_to_nearest_base(x, prec=2, base=0.2):\n","  return round(base * round(float(x)/base),prec)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rJLYVhv5v0Lk","colab_type":"code","colab":{}},"source":["def ReLU(Z):\n","\n","    #Return ReLU of input value\n","    A = np.maximum(0,Z)\n","    \n","    assert(A.shape == Z.shape)\n","    \n","    cache = Z \n","    return A, cache"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_4HhYFCzv3Dd","colab_type":"code","colab":{}},"source":["def ReLU_backward(dA,cache):\n","\n","    #Implement backward propogation of activation\n","    \n","    Z = cache\n","    dZ = np.array(dA, copy=True) # just converting dz to a correct object.\n","    \n","    # When z <= 0, you should set dz to 0 as well. \n","    dZ[Z <= 0] = 0\n","    \n","    assert (dZ.shape == Z.shape)\n","    \n","    return dZ"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iDdnNd5969cx","colab_type":"code","colab":{}},"source":["def linear(Z):\n","\n","    # implement a linear function\n","\n","    A =0.5*Z\n","\n","    assert(A.shape == Z.shape)\n","    \n","    cache = Z \n","    return A, cache"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lf89FU6469xk","colab_type":"code","colab":{}},"source":["def linear_backward(dA,cache):\n","    #Implement backward propogation of activation\n","    Z = cache\n","\n","    dZ = np.random.rand(Z.shape[0],Z.shape[1])\n","\n","    dZ[:,:] = 0.5\n","\n","    assert (dZ.shape == Z.shape)\n","    \n","    return dZ"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6KHQhuWhtjcc","colab_type":"code","colab":{}},"source":["def initialise_parameters(layer_dims):\n","    \n","    #Random initialisation of Ws and zero initialisation of bias vector\n","\n","    parameters = {}\n","    L = len(layer_dims)            # number of layers in the network\n","\n","    for l in range(1, L):\n","        parameters['W' + str(l)] = np.random.randn(layer_dims[l],layer_dims[l-1])*0.01\n","        parameters['b' + str(l)] = np.zeros((layer_dims[l],1))\n","        \n","        assert(parameters['W' + str(l)].shape == (layer_dims[l], layer_dims[l-1]))\n","        assert(parameters['b' + str(l)].shape == (layer_dims[l], 1))\n","\n","        \n","    return parameters"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nrc19O3xtkaB","colab_type":"code","colab":{}},"source":["def forward_prop(A, W, b):\n","\n","    #Implement forward propogation \n","    \n","    Z = np.dot(W,A)+b\n","    \n","    assert(Z.shape == (W.shape[0], A.shape[1]))\n","    cache = (A, W, b)\n","    \n","    return Z, cache"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UKuFTktuwm4m","colab_type":"code","colab":{}},"source":["def activation_forward_prop(A_prev, W, b, activation):\n","\n","    #Activation function step for forward propogation\n","\n","    if activation == \"relu\":\n","        Z, linear_cache = forward_prop(A_prev,W,b)\n","        A, activation_cache = ReLU(Z)\n","    \n","    elif activation == \"linear\":\n","        Z, linear_cache = forward_prop(A_prev,W,b)\n","        A, activation_cache = linear(Z)\n","\n","    assert (A.shape == (W.shape[0], A_prev.shape[1]))\n","    cache = (linear_cache, activation_cache)\n","\n","    return A, cache\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G3zsWE7_6CGU","colab_type":"code","colab":{}},"source":["def L_layer_forward_prop(X, parameters):\n","\n","    #Ensure that forward propogation is done for layer l\n","\n","    caches = []\n","    A = X\n","    L = len(parameters) // 2                  # number of layers in the neural network\n","    \n","    for l in range(1, L):\n","        A_prev = A \n","        A, cache = activation_forward_prop(A_prev,parameters['W' + str(l)],parameters['b' + str(l)],activation = \"relu\")\n","        caches.append(cache)\n","    \n","    AL, cache = activation_forward_prop(A,parameters['W' + str(L)],parameters['b' + str(L)],activation = \"relu\")\n","    caches.append(cache)\n","    \n","    assert(AL.shape == (1,X.shape[1]))\n","            \n","    return AL, caches"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PjildkexoqTV","colab_type":"code","colab":{}},"source":["#A mean squared error cost function is good for regression\n","\n","def cost_func(AL,Y):\n","\n","    #Implement a mean squared error cost function which is good for regression\n","\n","    m = Y.shape[1]\n","\n","    cost = (1/(2*m))*(np.sum(np.square(np.subtract(AL,Y))))\n","    return cost"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ak-QEwV3xlL3","colab_type":"code","colab":{}},"source":["def backward_prop(dZ, cache):\n","\n","    #Implemenet backward propogation\n","    \n","    A_prev, W, b = cache\n","    m = A_prev.shape[1]\n","\n","    dW = 1/m*np.dot(dZ,(A_prev.T))\n","    db = 1/m*(np.sum(dZ,axis=1, keepdims=True))\n","    dA_prev = np.dot((W.T),dZ)\n","    \n","    assert (dA_prev.shape == A_prev.shape)\n","    assert (dW.shape == W.shape)\n","    assert (db.shape == b.shape)\n","\n","    return dA_prev, dW, db"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kYKlPfc1_3-P","colab_type":"code","colab":{}},"source":["def activation_backward_prop(dA, cache, activation):\n","\n","    #The activation step for backward propogation\n","\n","    linear_cache, activation_cache = cache\n","    \n","    if activation == \"relu\":\n","        dZ = ReLU_backward(dA,activation_cache)\n","        dA_prev, dW, db = backward_prop(dZ,linear_cache)\n","\n","    elif activation == \"linear\":\n","        dZ = linear_backward(dA,activation_cache)\n","        dA_prev, dW, db = backward_prop(dZ,linear_cache)\n","        \n","    return dA_prev, dW, db"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v5Mc8JbW_64y","colab_type":"code","colab":{}},"source":["def L_layer_backward_prop(AL, Y, caches):\n","\n","    #Ensure that backward propogation is done for layer l\n","    \n","    grads = {}\n","    L = len(caches) # the number of layers\n","    Y = Y.reshape(AL.shape) # after this line, Y is the same shape as AL\n","    \n","    # Initializing the backpropagation\n","    dAL = (AL-Y) # derivative of mean squared error cost with respect to AL\n","    \n","    # Lth layer (RELU -> LINEAR) gradients. Inputs: \"dAL, current_cache\". Outputs: \"grads[\"dAL-1\"], grads[\"dWL\"], grads[\"dbL\"]\n","    current_cache = caches[L-1]\n","    grads[\"dA\" + str(L-1)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = activation_backward_prop(dAL,current_cache,activation=\"relu\")\n","    \n","    # Loop from l=L-2 to l=0\n","    for l in reversed(range(L-1)):\n","        # lth layer: (RELU -> LINEAR) gradients.\n","        current_cache = caches[l]\n","        dA_prev_temp = grads[\"dA\" + str(l+1)] #dA_prev_temp, dW_temp, db_temp = grads[\"dA\" + str(l+1)], grads[\"dW\" + str(l+2)], grads[\"db\" + str(l+2)]\n","        grads[\"dA\" + str(l)] = activation_backward_prop(dA_prev_temp,current_cache,activation=\"relu\")[0]\n","        grads[\"dW\" + str(l + 1)] = activation_backward_prop(dA_prev_temp,current_cache,activation=\"relu\")[1]\n","        grads[\"db\" + str(l + 1)] = activation_backward_prop(dA_prev_temp,current_cache,activation=\"relu\")[2]\n","\n","    return grads"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j5LW6QSYAPnt","colab_type":"code","colab":{}},"source":["def update_parameters(parameters, grads, learning_rate):\n","\n","    #Update the parameters using the grads from the previous function\n","    \n","    L = len(parameters) // 2 # number of layers in the neural network\n","\n","    # Update rule for each parameter. Use a for loop.\n","    for l in range(L):\n","        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - learning_rate*grads[\"dW\" + str(l + 1)]\n","        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - learning_rate*grads[\"db\" + str(l + 1)]\n","    return parameters"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q90IhRRrASMH","colab_type":"code","colab":{}},"source":["def predict(X, y, parameters):\n","\n","    #This returns the predictions of the neural network\n","    \n","    m = X.shape[1]\n","    p = np.zeros((1,m))\n","    \n","    # Forward propagation\n","    values, caches = L_layer_forward_prop(X, parameters)\n","\n","    for i in range(values.shape[1]):\n","        print(\"prediction: %f vs actual: %f \\n\" %(values[0][i], y[0][i]))\n","\n","\n","    list_comp = [round_num_to_nearest_base(values[0][i]) == round_num_to_nearest_base(y[0][i]) for i in range(values.shape[1])]\n","    \n","\n","    print(\"Accuracy: \"  + str(np.sum(list_comp)/m))\n","\n","    fig, ax = plt.subplots(figsize=(8,8))\n","    xy_line = [0,1,2,3,4]\n","    xy_max = [0.2,1.2,2.2,3.2,4.2]\n","    xy_min = [-0.2,0.8,1.8,2.8,3.8] #Not actually negative but provides perspective\n","    ax.scatter(np.array(y),np.array(values))\n","    ax.plot(xy_line, 'r--')\n","    ax.plot(xy_max, 'b--')\n","    ax.plot(xy_min, 'b--')\n","    ax.set_ylabel('Perdicted value')\n","    ax.set_xlabel('Actual value')\n","    plt.show()\n","        \n","    return values"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7LHpBULDDf-Y","colab_type":"code","colab":{}},"source":["def parameter_regression_model(X, Y, layers_dims, learning_rate = 0.025, num_iterations = 3000, print_cost=True):\n","\n","    costs = [] # keep track of cost\n","    \n","    parameters = initialise_parameters(layers_dims)\n","    \n","    # Loop (gradient descent)\n","    for i in range(0, num_iterations):\n","\n","\n","        AL, caches = L_layer_forward_prop(X, parameters)\n","\n","        cost = cost_func(AL, Y)\n","\n","        grads = L_layer_backward_prop(AL, Y, caches)\n","\n","        parameters = update_parameters(parameters, grads, learning_rate)\n","    \n","                \n","        # Print the cost every 5000 training examples\n","        if print_cost and i % 5000 == 0:\n","            print (\"Cost after iteration %i: %f\" %(i, cost))\n","        if print_cost and i % 5000 == 0:\n","            costs.append(cost)\n","\n","\n","    # plot the cost\n","    plt.plot(np.squeeze(costs))\n","    plt.ylabel('cost')\n","    plt.xlabel('iterations (per hundreds)')\n","    plt.title(\"Learning rate =\" + str(learning_rate))\n","    plt.show()\n","    \n","    return parameters"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zfk9uRWuFXkY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"executionInfo":{"status":"ok","timestamp":1598012889380,"user_tz":-60,"elapsed":768,"user":{"displayName":"Rahul Banerjee","photoUrl":"","userId":"02868075930645419834"}},"outputId":"9175dc4c-8d25-42c4-9290-7ea5e75d5107"},"source":["X_train = np.array(subparams_fid_int_train)\n","n_x = X_train.shape[0]\n","m_train = X_train.shape[1]\n","print(X_train.shape)\n","Y_train = np.array(comp_train).reshape((1,m_train))\n","print(Y_train.shape)\n","X_test = np.array(subparams_fid_int_test)\n","m_test = X_test.shape[1]\n","print(X_test.shape)\n","Y_test = np.array(comp_test).reshape((1,m_test))\n","print(Y_test.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(9, 818)\n","(1, 818)\n","(9, 204)\n","(1, 204)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xHNYM-zTFbx1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1598012889787,"user_tz":-60,"elapsed":693,"user":{"displayName":"Rahul Banerjee","photoUrl":"","userId":"02868075930645419834"}},"outputId":"ef41c0ea-d5b9-4967-cc6a-6775577d6e48"},"source":["#Checking\n","\"\"\"print(round_num_to_nearest_base(1.31))\n","print(round_num_to_nearest_base(1.77))\n","print(round_num_to_nearest_base(1.94))\n","print(round_num_to_nearest_base(100.15))\"\"\""],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'print(round_num_to_nearest_base(1.31))\\nprint(round_num_to_nearest_base(1.77))\\nprint(round_num_to_nearest_base(1.94))\\nprint(round_num_to_nearest_base(100.15))'"]},"metadata":{"tags":[]},"execution_count":53}]},{"cell_type":"code","metadata":{"id":"I_TuOj7XFeEi","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"ae857d9b-75ad-4d61-a060-65d63b7926b5"},"source":["layers_dims = [9,18,16,1]\n","\n","#While the cost plateuas, which slows the neural network down, the accuracy of the predictions is greater \n","\n","best_params = parameter_regression_model(X_train, Y_train, layers_dims, num_iterations = 120000, print_cost = True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Cost after iteration 0: 0.919907\n","Cost after iteration 5000: 0.047013\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZO7WDAMC_kQe","colab_type":"code","colab":{}},"source":["#print(best_params)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ng5g8f-gGaaz","colab_type":"code","colab":{}},"source":["prediction_train = predict(X_train, Y_train, best_params)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"afi0vLm2GfYU","colab_type":"code","colab":{}},"source":["prediction_test = predict(X_test, Y_test, best_params)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oE8EzoO2UwmX","colab_type":"code","colab":{}},"source":["#Current accuracy values suggest underfitting as both training and testing accuracy are low"],"execution_count":null,"outputs":[]}]}